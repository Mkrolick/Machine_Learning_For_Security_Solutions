{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e66ed0-0ad7-496f-87d0-d5c17aeb9870",
   "metadata": {},
   "source": [
    "# Final Practice\n",
    "Today is all about practice.\n",
    "You are given:\n",
    "- a set of people that registered to your authentication system\n",
    "    - with the file \"people.csv\" containing all their info\n",
    "    - their associated reference embeddings in \"people_embeddings.npy\"\n",
    "- a set of connections that will be used to train and validate the defense systems you deemed useful. This includes:\n",
    "    - The file describing their connections: \"train_connections.csv\"\n",
    "    - The associated connection embeddings: \"train_connections_embeddings.npy\"\n",
    "- a test set of connections. The main question here is: which one of those test connections would you allow in? The set includes:\n",
    "    - The file describing their connections: \"test_connections.csv\"\n",
    "    - The associated connection embeddings: \"test_connections_embeddings.npy\"\n",
    "    \n",
    "Your mission is to produce a list of booleans 'predicted_test_labels', of the same length as the 'test_connections.csv', each boolean being True if you let then connection in and False otherwise. <br>\n",
    "Use the \"eval(predicted_test_labels)\" function to get the accuracy of your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e333a2f7-5ebe-4a93-b800-86bce0b3be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\malco\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\malco\\anaconda3\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\malco\\anaconda3\\lib\\site-packages (from xgboost) (1.11.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "860fe6cd-95ac-4ccc-b745-2c8d0f4cc635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "def load_files(csv_file=\"\",npy_file=\"\"): return pd.read_csv(csv_file), np.load(npy_file, allow_pickle=True)\n",
    "\n",
    "train_connections, train_embeddings = load_files(csv_file=\"train_connections.csv\", npy_file=\"train_connections_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36eccc49-8d82-44db-8911-d1d7250f005f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33401\n"
     ]
    }
   ],
   "source": [
    "#Your code\n",
    "labels_list = [1 if connection_true else 0 for connection_true in train_connections['true_attempt']]\n",
    "labels = np.array(labels_list) #we transform the list in a np.array to ease the next steps (idk why, but sklearn seems to like it...)\n",
    "\n",
    "data_train = train_embeddings\n",
    "labels_train = labels\n",
    "\n",
    "#make labels 2 d\n",
    "#labels_train = np.array([[1, 0] if label == 0 else [0, 1] for label in labels_train])\n",
    "print(len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f03def7e-2c89-44cd-bee7-600b6a3af81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6599, 128)\n"
     ]
    }
   ],
   "source": [
    "# load test_connections_embeddings.npy\n",
    "test_embeddings = np.load(\"test_connections_embeddings.npy\")\n",
    "print(test_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(predicted_test_labels):\n",
    "    targets = np.load('solution.npy')\n",
    "    accuracy = np.sum(targets==predicted_test_labels)/len(predicted_test_labels)\n",
    "    print(f\"The accuracy of your system is {100*accuracy}%!\")\n",
    "    \n",
    "#eval(predicted_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot distribution of labels in hist bucket = 2\n",
    "# normalize axis to total percentage\n",
    "\n",
    "plt.hist(labels_train, bins=2, edgecolor='black', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a20dcd4-413f-4a30-9553-f97190559414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of your system is 77.7390513714199%!\n"
     ]
    }
   ],
   "source": [
    "# run xgboost for kagggle competition\n",
    "\n",
    "\n",
    "#for i in range(1, 10):\n",
    "    # train model\n",
    "#    xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42, n_estimators=800, max_depth=i, )\n",
    "#    xgb_model.fit(data_train, labels_train)\n",
    "\n",
    "    # predict test labels\n",
    "#    predicted_test_labels = xgb_model.predict(test_embeddings)\n",
    "\n",
    "#    print(i, eval(predicted_test_labels))\n",
    "    # 76.49% accuracy\n",
    "\n",
    "\n",
    "# 800, 3 -> 78.1 %\n",
    "\n",
    "# 900, 2 -> 78.5% , seed 42\n",
    "\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(learning_rate = 0.2, objective=\"binary:logistic\", random_state=42, n_estimators=800, max_depth=2)\n",
    "\n",
    "xgb_model.fit(data_train, labels_train)\n",
    "\n",
    "predicted_test_labels = xgb_model.predict(test_embeddings)\n",
    "\n",
    "eval(predicted_test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab92cb77-6d23-4204-a963-d4d0ea31080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision trees with xgboost\n",
    "#from sklearn.model_selection import KFold\n",
    "#\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=122)\n",
    "#for train_index, test_index in kf.split(data_train):\n",
    "##    xgb_model = xgb.XGBClassifier(random_state=42).fit(\n",
    "#    data_train[train_index], labels[train_index])\n",
    "#\n",
    "#predicted_test_labels = xgb_model.predict(test_embeddings)\n",
    "\n",
    "#print(eval(predicted_test_labels))\n",
    "\n",
    "# 75.49628731626004%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a random forests models\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#rf_model = RandomForestClassifier(n_estimators=40, max_depth=3, random_state=0)\n",
    "\n",
    "#rf_model.fit(data_train, labels_train)\n",
    "\n",
    "#predicted_test_labels = rf_model.predict(test_embeddings)\n",
    "\n",
    "#eval(predicted_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a random forests regressor\n",
    "\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#rf_model = RandomForestRegressor(n_estimators=40, max_depth=3, random_state=0)\n",
    "\n",
    "#rf_model.fit(data_train, labels_train)\n",
    "\n",
    "#predicted_test_labels = rf_model.predict(test_embeddings)\n",
    "#eval(predicted_test_labels)\n",
    "\n",
    "# LMAOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3178c966-7fd7-423d-88b8-022ed90a2be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a non linear model SVM\n",
    "#from sklearn import svm\n",
    "\n",
    "#clf = svm.SVC()\n",
    "#clf.fit(data_train, labels_train)\n",
    "\n",
    "#predicted_test_labels = clf.predict(test_embeddings)\n",
    "\n",
    "\n",
    "# 76.6% accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a5ac93b-d884-49fc-a1df-be9408268e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a non linear svm with a kernel\n",
    "\n",
    "#clf = svm.NuSVC(gamma=\"auto\")\n",
    "#clf.fit(data_train, labels_train)\n",
    "\n",
    "#predicted_test_labels = clf.predict(test_embeddings)\n",
    "\n",
    "# Wow that was 71% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a voting system with XGBoost and Random forest\n",
    "\n",
    "#predicted_test_labels = np.array([1 if (xgb_model.predict([test_embeddings[i]]) + rf_model.predict([test_embeddings[i]])) > 1 else 0 for i in range(len(test_embeddings))])\n",
    "\n",
    "#eval(predicted_test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of your system is 74.58705864524929%!\n"
     ]
    }
   ],
   "source": [
    "# use logisitc regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(data_train, labels_train)\n",
    "\n",
    "predicted_test_labels = clf.predict(test_embeddings)\n",
    "\n",
    "eval(predicted_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_76 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43393 (169.50 KB)\n",
      "Trainable params: 43393 (169.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1028/1044 [============================>.] - ETA: 0s - loss: 1.3132 - accuracy: 0.7480Predictions for epoch 1:\n",
      "207/207 [==============================] - 0s 739us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 3s 2ms/step - loss: 1.3018 - accuracy: 0.7484\n",
      "Epoch 2/40\n",
      "1020/1044 [============================>.] - ETA: 0s - loss: 0.5771 - accuracy: 0.7500Predictions for epoch 2:\n",
      "207/207 [==============================] - 0s 724us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5771 - accuracy: 0.7499\n",
      "Epoch 3/40\n",
      "1035/1044 [============================>.] - ETA: 0s - loss: 0.5750 - accuracy: 0.7496Predictions for epoch 3:\n",
      "207/207 [==============================] - 0s 748us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5746 - accuracy: 0.7499\n",
      "Epoch 4/40\n",
      "1040/1044 [============================>.] - ETA: 0s - loss: 0.5715 - accuracy: 0.7499Predictions for epoch 4:\n",
      "207/207 [==============================] - 0s 738us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5714 - accuracy: 0.7499\n",
      "Epoch 5/40\n",
      "1042/1044 [============================>.] - ETA: 0s - loss: 0.5681 - accuracy: 0.7499Predictions for epoch 5:\n",
      "207/207 [==============================] - 0s 771us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5681 - accuracy: 0.7499\n",
      "Epoch 6/40\n",
      "1032/1044 [============================>.] - ETA: 0s - loss: 0.5628 - accuracy: 0.7501Predictions for epoch 6:\n",
      "207/207 [==============================] - 0s 774us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5631 - accuracy: 0.7499\n",
      "Epoch 7/40\n",
      "1042/1044 [============================>.] - ETA: 0s - loss: 0.5593 - accuracy: 0.7499Predictions for epoch 7:\n",
      "207/207 [==============================] - 0s 806us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5593 - accuracy: 0.7499\n",
      "Epoch 8/40\n",
      "1038/1044 [============================>.] - ETA: 0s - loss: 0.5565 - accuracy: 0.7499Predictions for epoch 8:\n",
      "207/207 [==============================] - 0s 739us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5565 - accuracy: 0.7499\n",
      "Epoch 9/40\n",
      "1044/1044 [==============================] - ETA: 0s - loss: 0.5531 - accuracy: 0.7499Predictions for epoch 9:\n",
      "207/207 [==============================] - 0s 792us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5531 - accuracy: 0.7499\n",
      "Epoch 10/40\n",
      "1036/1044 [============================>.] - ETA: 0s - loss: 0.5490 - accuracy: 0.7499Predictions for epoch 10:\n",
      "207/207 [==============================] - 0s 700us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5489 - accuracy: 0.7499\n",
      "Epoch 11/40\n",
      "1030/1044 [============================>.] - ETA: 0s - loss: 0.5472 - accuracy: 0.7500Predictions for epoch 11:\n",
      "207/207 [==============================] - 0s 762us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5472 - accuracy: 0.7499\n",
      "Epoch 12/40\n",
      "1019/1044 [============================>.] - ETA: 0s - loss: 0.5446 - accuracy: 0.7500Predictions for epoch 12:\n",
      "207/207 [==============================] - 0s 701us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7499\n",
      "Epoch 13/40\n",
      "1032/1044 [============================>.] - ETA: 0s - loss: 0.5444 - accuracy: 0.7501Predictions for epoch 13:\n",
      "207/207 [==============================] - 0s 816us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7499\n",
      "Epoch 14/40\n",
      "1021/1044 [============================>.] - ETA: 0s - loss: 0.5430 - accuracy: 0.7499Predictions for epoch 14:\n",
      "207/207 [==============================] - 0s 716us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7499\n",
      "Epoch 15/40\n",
      "1041/1044 [============================>.] - ETA: 0s - loss: 0.5410 - accuracy: 0.7499Predictions for epoch 15:\n",
      "207/207 [==============================] - 0s 782us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5410 - accuracy: 0.7499\n",
      "Epoch 16/40\n",
      "1034/1044 [============================>.] - ETA: 0s - loss: 0.5392 - accuracy: 0.7500Predictions for epoch 16:\n",
      "207/207 [==============================] - 0s 708us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.7499\n",
      "Epoch 17/40\n",
      "1010/1044 [============================>.] - ETA: 0s - loss: 0.5376 - accuracy: 0.7498Predictions for epoch 17:\n",
      "207/207 [==============================] - 0s 761us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5379 - accuracy: 0.7499\n",
      "Epoch 18/40\n",
      "1031/1044 [============================>.] - ETA: 0s - loss: 0.5379 - accuracy: 0.7499Predictions for epoch 18:\n",
      "207/207 [==============================] - 0s 763us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5379 - accuracy: 0.7499\n",
      "Epoch 19/40\n",
      "1025/1044 [============================>.] - ETA: 0s - loss: 0.5354 - accuracy: 0.7498Predictions for epoch 19:\n",
      "207/207 [==============================] - 0s 781us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7499\n",
      "Epoch 20/40\n",
      "1037/1044 [============================>.] - ETA: 0s - loss: 0.5354 - accuracy: 0.7499Predictions for epoch 20:\n",
      "207/207 [==============================] - 0s 714us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7499\n",
      "Epoch 21/40\n",
      "1019/1044 [============================>.] - ETA: 0s - loss: 0.5333 - accuracy: 0.7496Predictions for epoch 21:\n",
      "207/207 [==============================] - 0s 825us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.7499\n",
      "Epoch 22/40\n",
      "1013/1044 [============================>.] - ETA: 0s - loss: 0.5331 - accuracy: 0.7499Predictions for epoch 22:\n",
      "207/207 [==============================] - 0s 756us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7499\n",
      "Epoch 23/40\n",
      "1026/1044 [============================>.] - ETA: 0s - loss: 0.5326 - accuracy: 0.7504Predictions for epoch 23:\n",
      "207/207 [==============================] - 0s 790us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5326 - accuracy: 0.7499\n",
      "Epoch 24/40\n",
      "1027/1044 [============================>.] - ETA: 0s - loss: 0.5302 - accuracy: 0.7500Predictions for epoch 24:\n",
      "207/207 [==============================] - 0s 722us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.7499\n",
      "Epoch 25/40\n",
      "1037/1044 [============================>.] - ETA: 0s - loss: 0.5305 - accuracy: 0.7497Predictions for epoch 25:\n",
      "207/207 [==============================] - 0s 785us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.7499\n",
      "Epoch 26/40\n",
      "1030/1044 [============================>.] - ETA: 0s - loss: 0.5292 - accuracy: 0.7503Predictions for epoch 26:\n",
      "207/207 [==============================] - 0s 734us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7499\n",
      "Epoch 27/40\n",
      "1015/1044 [============================>.] - ETA: 0s - loss: 0.5299 - accuracy: 0.7502Predictions for epoch 27:\n",
      "207/207 [==============================] - 0s 754us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7499\n",
      "Epoch 28/40\n",
      "1031/1044 [============================>.] - ETA: 0s - loss: 0.5289 - accuracy: 0.7501Predictions for epoch 28:\n",
      "207/207 [==============================] - 0s 804us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5289 - accuracy: 0.7499\n",
      "Epoch 29/40\n",
      "1027/1044 [============================>.] - ETA: 0s - loss: 0.5302 - accuracy: 0.7503Predictions for epoch 29:\n",
      "207/207 [==============================] - 0s 748us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7499\n",
      "Epoch 30/40\n",
      "1013/1044 [============================>.] - ETA: 0s - loss: 0.5263 - accuracy: 0.7498Predictions for epoch 30:\n",
      "207/207 [==============================] - 0s 809us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5269 - accuracy: 0.7499\n",
      "Epoch 31/40\n",
      "1023/1044 [============================>.] - ETA: 0s - loss: 0.5306 - accuracy: 0.7498Predictions for epoch 31:\n",
      "207/207 [==============================] - 0s 776us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7499\n",
      "Epoch 32/40\n",
      "1029/1044 [============================>.] - ETA: 0s - loss: 0.5274 - accuracy: 0.7498Predictions for epoch 32:\n",
      "207/207 [==============================] - 0s 784us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5274 - accuracy: 0.7499\n",
      "Epoch 33/40\n",
      "1036/1044 [============================>.] - ETA: 0s - loss: 0.5293 - accuracy: 0.7498Predictions for epoch 33:\n",
      "207/207 [==============================] - 0s 788us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7499\n",
      "Epoch 34/40\n",
      "1012/1044 [============================>.] - ETA: 0s - loss: 0.5292 - accuracy: 0.7498Predictions for epoch 34:\n",
      "207/207 [==============================] - 0s 724us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7499\n",
      "Epoch 35/40\n",
      "1040/1044 [============================>.] - ETA: 0s - loss: 0.5262 - accuracy: 0.7497Predictions for epoch 35:\n",
      "207/207 [==============================] - 0s 802us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5261 - accuracy: 0.7499\n",
      "Epoch 36/40\n",
      "1013/1044 [============================>.] - ETA: 0s - loss: 0.5250 - accuracy: 0.7501Predictions for epoch 36:\n",
      "207/207 [==============================] - 0s 732us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5253 - accuracy: 0.7499\n",
      "Epoch 37/40\n",
      "1021/1044 [============================>.] - ETA: 0s - loss: 0.5283 - accuracy: 0.7499Predictions for epoch 37:\n",
      "207/207 [==============================] - 0s 773us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5285 - accuracy: 0.7499\n",
      "Epoch 38/40\n",
      "1026/1044 [============================>.] - ETA: 0s - loss: 0.5247 - accuracy: 0.7501Predictions for epoch 38:\n",
      "207/207 [==============================] - 0s 724us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5251 - accuracy: 0.7499\n",
      "Epoch 39/40\n",
      "1029/1044 [============================>.] - ETA: 0s - loss: 0.5273 - accuracy: 0.7503Predictions for epoch 39:\n",
      "207/207 [==============================] - 0s 751us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5276 - accuracy: 0.7499\n",
      "Epoch 40/40\n",
      "1027/1044 [============================>.] - ETA: 0s - loss: 0.5264 - accuracy: 0.7502Predictions for epoch 40:\n",
      "207/207 [==============================] - 0s 772us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5266 - accuracy: 0.7499\n",
      "207/207 [==============================] - 0s 731us/step\n",
      "The accuracy of your system is 75.05682679193816%!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\malco\\OneDrive\\Documents\\GitHub\\Machine_Learning_For_Security_Solutions\\Week 9\\Final Practice.ipynb Cell 18\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/malco/OneDrive/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X22sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# plot a graph of validation accuracy and loss over epochs\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/malco/OneDrive/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X22sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/malco/OneDrive/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X22sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(model\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/malco/OneDrive/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X22sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(model\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/malco/OneDrive/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X22sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mmodel accuracy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.02)),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.02)),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.02)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dropout(0.1),  # Dropout for regularization\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "model.build(input_shape=(None, 128))\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# produce prediction on test data after each epoch \n",
    "\n",
    "# make callback\n",
    "\n",
    "class PredictionCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        print(\"Predictions for epoch {}:\".format(epoch+1))\n",
    "        predictions = model.predict(test_embeddings)\n",
    "        a = []\n",
    "        for val in predictions:\n",
    "            a.append(round(val[0]))\n",
    "        eval(a)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "# train the model\n",
    "model.fit(train_embeddings, labels, epochs=40, callbacks=[PredictionCallback()])\n",
    "\n",
    "\n",
    "\n",
    "# To make predictions:\n",
    "predictions = model.predict(test_embeddings)\n",
    "\n",
    "\n",
    "a = []\n",
    "for val in predictions:\n",
    "    \n",
    "    a.append(round(val[0]))\n",
    "\n",
    "eval(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33401\n",
      "6599\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [33401, 6599]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\malco\\OneDrive\\Documents\\GitHub\\Machine_Learning_For_Security_Solutions\\Week 9\\Final Practice.ipynb Cell 19\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/malco/OneDrive/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(labels))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/malco/OneDrive/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(predictions))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/malco/OneDrive/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m fpr, tpr, thresholds \u001b[39m=\u001b[39m roc_curve(labels, predictions)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/malco/OneDrive/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X42sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m roc_auc \u001b[39m=\u001b[39m auc(fpr, tpr)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/malco/OneDrive/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X42sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure()\n",
      "File \u001b[1;32mc:\\Users\\malco\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\malco\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1094\u001b[0m, in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m    993\u001b[0m     {\n\u001b[0;32m    994\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1003\u001b[0m     y_true, y_score, \u001b[39m*\u001b[39m, pos_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, drop_intermediate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m ):\n\u001b[0;32m   1005\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m \n\u001b[0;32m   1007\u001b[0m \u001b[39m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[39m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1094\u001b[0m     fps, tps, thresholds \u001b[39m=\u001b[39m _binary_clf_curve(\n\u001b[0;32m   1095\u001b[0m         y_true, y_score, pos_label\u001b[39m=\u001b[39mpos_label, sample_weight\u001b[39m=\u001b[39msample_weight\n\u001b[0;32m   1096\u001b[0m     )\n\u001b[0;32m   1098\u001b[0m     \u001b[39m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m     \u001b[39m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     \u001b[39m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1105\u001b[0m     \u001b[39m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[0;32m   1106\u001b[0m     \u001b[39m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m     \u001b[39mif\u001b[39;00m drop_intermediate \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(fps) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\malco\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:805\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m pos_label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)):\n\u001b[0;32m    803\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[1;32m--> 805\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m    806\u001b[0m y_true \u001b[39m=\u001b[39m column_or_1d(y_true)\n\u001b[0;32m    807\u001b[0m y_score \u001b[39m=\u001b[39m column_or_1d(y_score)\n",
      "File \u001b[1;32mc:\\Users\\malco\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    407\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    408\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    412\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [33401, 6599]"
     ]
    }
   ],
   "source": [
    "#plot a ROC curve\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "print(len(labels))\n",
    "print(len(predictions))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(labels, predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {})'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_81 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53792 (210.12 KB)\n",
      "Trainable params: 53792 (210.12 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1044/1044 [==============================] - 2s 1ms/step - loss: -245220261888.0000 - accuracy: 0.0087\n",
      "Epoch 2/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -26427181236224.0000 - accuracy: 0.0093\n",
      "Epoch 3/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -294301594550272.0000 - accuracy: 0.0094\n",
      "Epoch 4/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -1428565312667648.0000 - accuracy: 0.0093\n",
      "Epoch 5/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -4505332109803520.0000 - accuracy: 0.0094\n",
      "Epoch 6/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -11114443354144768.0000 - accuracy: 0.0097\n",
      "Epoch 7/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -23438476200378368.0000 - accuracy: 0.0094\n",
      "Epoch 8/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -44167515231748096.0000 - accuracy: 0.0094\n",
      "Epoch 9/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -77075730747359232.0000 - accuracy: 0.0094\n",
      "Epoch 10/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -126552800514539520.0000 - accuracy: 0.0094\n",
      "Epoch 11/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -198157387171889152.0000 - accuracy: 0.0094\n",
      "Epoch 12/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -298570114779840512.0000 - accuracy: 0.0094\n",
      "Epoch 13/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -434541529466404864.0000 - accuracy: 0.0094\n",
      "Epoch 14/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -616569562095157248.0000 - accuracy: 0.0094\n",
      "Epoch 15/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -856903218876121088.0000 - accuracy: 0.0094\n",
      "Epoch 16/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -1165148348785623040.0000 - accuracy: 0.0094\n",
      "Epoch 17/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -1554335332843913216.0000 - accuracy: 0.0094\n",
      "Epoch 18/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -2041293364745207808.0000 - accuracy: 0.0094\n",
      "Epoch 19/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -2643154210039791616.0000 - accuracy: 0.0094\n",
      "Epoch 20/20\n",
      "1044/1044 [==============================] - 1s 1ms/step - loss: -3380228872149663744.0000 - accuracy: 0.0094\n",
      "207/207 [==============================] - 0s 808us/step\n"
     ]
    }
   ],
   "source": [
    "# create an autoencoder with keras\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(128,)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# train the model\n",
    "\n",
    "model.fit(train_embeddings, train_embeddings, epochs=20)\n",
    "\n",
    "# save predictions\n",
    "\n",
    "new_embeddings = model.predict(test_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run xgboost for kagggle competition\n",
    "\n",
    "\n",
    "#for i in range(1, 10):\n",
    "    # train model\n",
    "#    xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42, n_estimators=800, max_depth=i, )\n",
    "#    xgb_model.fit(data_train, labels_train)\n",
    "\n",
    "    # predict test labels\n",
    "#    predicted_test_labels = xgb_model.predict(test_embeddings)\n",
    "\n",
    "#    print(i, eval(predicted_test_labels))\n",
    "    # 76.49% accuracy\n",
    "\n",
    "\n",
    "# 800, 3 -> 78.1 %\n",
    "\n",
    "# 900, 2 -> 78.5% , seed 42\n",
    "\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(learning_rate = 0.2, objective=\"binary:logistic\", random_state=42, n_estimators=800, max_depth=2)\n",
    "\n",
    "xgb_model.fit(data_train, labels_train)\n",
    "\n",
    "predicted_test_labels = xgb_model.predict(test_embeddings)\n",
    "\n",
    "eval(predicted_test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26881 (105.00 KB)\n",
      "Trainable params: 26881 (105.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1033/1044 [============================>.] - ETA: 0s - loss: 1.0590 - accuracy: 0.7488Predictions for epoch 1:\n",
      "207/207 [==============================] - 0s 1ms/step\n",
      "The accuracy of your system is 75.05682679193816%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 4s 3ms/step - loss: 1.0539 - accuracy: 0.7489\n",
      "Epoch 2/100\n",
      "1026/1044 [============================>.] - ETA: 0s - loss: 0.5593 - accuracy: 0.7507Predictions for epoch 2:\n",
      "207/207 [==============================] - 0s 1ms/step\n",
      "The accuracy of your system is 75.66297923927868%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 3s 2ms/step - loss: 0.5595 - accuracy: 0.7502\n",
      "Epoch 3/100\n",
      "1042/1044 [============================>.] - ETA: 0s - loss: 0.5507 - accuracy: 0.7524Predictions for epoch 3:\n",
      "207/207 [==============================] - 0s 1ms/step\n",
      "The accuracy of your system is 75.01136535838764%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 3s 2ms/step - loss: 0.5506 - accuracy: 0.7524\n",
      "Epoch 4/100\n",
      "1029/1044 [============================>.] - ETA: 0s - loss: 0.5402 - accuracy: 0.7541Predictions for epoch 4:\n",
      "207/207 [==============================] - 0s 1ms/step\n",
      "The accuracy of your system is 74.35975147749659%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 2s 2ms/step - loss: 0.5405 - accuracy: 0.7536\n",
      "Epoch 5/100\n",
      "1028/1044 [============================>.] - ETA: 0s - loss: 0.5344 - accuracy: 0.7549Predictions for epoch 5:\n",
      "207/207 [==============================] - 0s 1ms/step\n",
      "The accuracy of your system is 74.20821336566146%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 3s 2ms/step - loss: 0.5340 - accuracy: 0.7554\n",
      "Epoch 6/100\n",
      "1032/1044 [============================>.] - ETA: 0s - loss: 0.5286 - accuracy: 0.7569Predictions for epoch 6:\n",
      "207/207 [==============================] - 0s 2ms/step\n",
      "The accuracy of your system is 75.48113350507653%!\n",
      "\n",
      "\n",
      "1044/1044 [==============================] - 3s 3ms/step - loss: 0.5285 - accuracy: 0.7569\n",
      "Epoch 7/100\n",
      " 432/1044 [===========>..................] - ETA: 1s - loss: 0.5200 - accuracy: 0.7576"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/malcolmkrolick/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week 9/Final Practice.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/malcolmkrolick/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X23sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/malcolmkrolick/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X23sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# train the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/malcolmkrolick/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X23sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_embeddings, labels, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[PredictionCallback()])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/malcolmkrolick/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X23sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# To make predictions:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/malcolmkrolick/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X23sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(test_embeddings)\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine_Learning_For_Security_Solutions/MLSecuritySolutions/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine_Learning_For_Security_Solutions/MLSecuritySolutions/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine_Learning_For_Security_Solutions/MLSecuritySolutions/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine_Learning_For_Security_Solutions/MLSecuritySolutions/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine_Learning_For_Security_Solutions/MLSecuritySolutions/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine_Learning_For_Security_Solutions/MLSecuritySolutions/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine_Learning_For_Security_Solutions/MLSecuritySolutions/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine_Learning_For_Security_Solutions/MLSecuritySolutions/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine_Learning_For_Security_Solutions/MLSecuritySolutions/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine_Learning_For_Security_Solutions/MLSecuritySolutions/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine_Learning_For_Security_Solutions/MLSecuritySolutions/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create a deep learning model using primarily self attension\n",
    "\n",
    "# Define the model\n",
    "\n",
    "# import keras\n",
    "\n",
    "\n",
    "\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(128,), kernel_regularizer=keras.regularizers.l2(0.02)),  # Input layer with ReLU activation\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.02)),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(32, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# produce prediction on test data after each epoch \n",
    "\n",
    "# make callback\n",
    "\n",
    "class PredictionCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        print(\"Predictions for epoch {}:\".format(epoch+1))\n",
    "        predictions = model.predict(test_embeddings)\n",
    "        a = []\n",
    "        for val in predictions:\n",
    "            a.append(round(val[0]))\n",
    "        eval(a)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "# train the model\n",
    "model.fit(train_embeddings, labels, epochs=100, callbacks=[PredictionCallback()])\n",
    "\n",
    "\n",
    "\n",
    "# To make predictions:\n",
    "predictions = model.predict(test_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f722227a-bec0-4375-9cc8-32bd51edca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malcolmkrolick/Documents/GitHub/Machine_Learning_For_Security_Solutions/MLSecuritySolutions/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Deep learning \n",
    "\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#import numpy as np\n",
    "\n",
    "#takes in 128 vector and outputs a 1 or 0\n",
    "\n",
    "#hidden_layer_sizes = (128, 64, 32, 16, 8, 4, 2)\n",
    "\n",
    "#clf = MLPClassifier(random_state=1, max_iter=10, hidden_layer_sizes=hidden_layer_sizes, batch_size=40).fit(data_train, labels_train)\n",
    "#predicted_test_labels = clf.predict(test_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of your system is 72.07152598878618%!\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "\n",
    "\n",
    "for val in predicted_test_labels:\n",
    "    a.append(val)\n",
    "\n",
    "eval(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of your system is 72.73829368086074%!\n",
      "2 None\n",
      "The accuracy of your system is 71.69268070919837%!\n",
      "3 None\n",
      "The accuracy of your system is 72.17760266707077%!\n",
      "4 None\n",
      "The accuracy of your system is 71.859372632217%!\n",
      "5 None\n",
      "The accuracy of your system is 72.48067889074102%!\n",
      "6 None\n",
      "The accuracy of your system is 71.57145021973025%!\n",
      "7 None\n",
      "The accuracy of your system is 72.11698742233672%!\n",
      "8 None\n",
      "The accuracy of your system is 71.67752689801486%!\n",
      "9 None\n"
     ]
    }
   ],
   "source": [
    "# use KNN\n",
    "\n",
    "#for i in range(2, 10):\n",
    "#    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "#    knn.fit(data_train, labels_train)\n",
    "\n",
    "#    predicted_test_labels = knn.predict(test_embeddings)\n",
    "#    print(i, eval(predicted_test_labels))\n",
    "\n",
    "\n",
    "# 72% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "\n",
    "#def date_to_num(date):\n",
    "#    h_,d_ = date.split(' ')\n",
    "#    h,m,s = h_.split(':')\n",
    "#    d,mo,y = d_.split('-')\n",
    "#    y = int(y)-2019\n",
    "#    return int(s) + 60*(int(m) + 60*(int(h) + 24*(int(d) + 29*(int(mo) + 12*y))))\n",
    "\n",
    "#dates = list(train_connections['dates']) # list of the ips, as strings: '255.255.255.255'\n",
    "#years = [int(date.split('-')[-1]) for date in dates]\n",
    "#print(f\"The years range from {np.min(years)} to {np.max(years)}\")\n",
    "#print(f\"We can go from the str :'{dates[0]}' to a global number representing the total date from 2019 in seconds: {date_to_num(dates[0])}\")\n",
    "#train_data = np.array([ date_to_num(date) for date in dates]) #now we have an array, composed of lists ['255','255','255','255']\n",
    "#train_data = train_data.astype(int) #we convert it to int as we want to deal with numbers here, which gives us something like [255, 255, 255, 255]\n",
    "#print(f\"the shape of the train data is: {train_data.shape}\")\n",
    "\n",
    "#train_data_sorted = np.array(sorted(train_data))\n",
    "#diff = train_data_sorted[1:] - train_data_sorted[:-1]\n",
    "#plt.hist(diff, bins=100)\n",
    "#plt.show()\n",
    "\n",
    "#cluster_labels = AgglomerativeClustering(distance_threshold=60*60, n_clusters=None).fit_predict(train_data.reshape(-1,1)) #finding which dates are in which cluster\n",
    "# we don't chose the number of clusters, but if 2 samples are separated by more than 1hour, then it's a new group\n",
    "#print(f\"Found {len(set(cluster_labels))} clusters of connections hapening in the same hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malcolmkrolick/Documents/GitHub/Machine_Learning_For_Security_Solutions/MLSecuritySolutions/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/malcolmkrolick/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week 9/Final Practice.ipynb Cell 14\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/malcolmkrolick/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# use k means\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/malcolmkrolick/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m KMeans\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/malcolmkrolick/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m kmeans \u001b[39m=\u001b[39m KMeans(n_clusters\u001b[39m=\u001b[39;49m\u001b[39m4000\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(data_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/malcolmkrolick/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m predicted_test_labels \u001b[39m=\u001b[39m kmeans\u001b[39m.\u001b[39mpredict(test_embeddings)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/malcolmkrolick/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39meval\u001b[39m(predicted_test_labels))\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine_Learning_For_Security_Solutions/MLSecuritySolutions/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine_Learning_For_Security_Solutions/MLSecuritySolutions/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1519\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1515\u001b[0m best_inertia, best_labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_init):\n\u001b[1;32m   1518\u001b[0m     \u001b[39m# Initialize centers\u001b[39;00m\n\u001b[0;32m-> 1519\u001b[0m     centers_init \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_centroids(\n\u001b[1;32m   1520\u001b[0m         X,\n\u001b[1;32m   1521\u001b[0m         x_squared_norms\u001b[39m=\u001b[39;49mx_squared_norms,\n\u001b[1;32m   1522\u001b[0m         init\u001b[39m=\u001b[39;49minit,\n\u001b[1;32m   1523\u001b[0m         random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m   1524\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1525\u001b[0m     )\n\u001b[1;32m   1526\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m   1527\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInitialization complete\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine_Learning_For_Security_Solutions/MLSecuritySolutions/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1019\u001b[0m, in \u001b[0;36m_BaseKMeans._init_centroids\u001b[0;34m(self, X, x_squared_norms, init, random_state, sample_weight, init_size, n_centroids)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     sample_weight \u001b[39m=\u001b[39m sample_weight[init_indices]\n\u001b[1;32m   1018\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(init, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m init \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mk-means++\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 1019\u001b[0m     centers, _ \u001b[39m=\u001b[39m _kmeans_plusplus(\n\u001b[1;32m   1020\u001b[0m         X,\n\u001b[1;32m   1021\u001b[0m         n_clusters,\n\u001b[1;32m   1022\u001b[0m         random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m   1023\u001b[0m         x_squared_norms\u001b[39m=\u001b[39;49mx_squared_norms,\n\u001b[1;32m   1024\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1025\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(init, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m init \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrandom\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1027\u001b[0m     seeds \u001b[39m=\u001b[39m random_state\u001b[39m.\u001b[39mchoice(\n\u001b[1;32m   1028\u001b[0m         n_samples,\n\u001b[1;32m   1029\u001b[0m         size\u001b[39m=\u001b[39mn_clusters,\n\u001b[1;32m   1030\u001b[0m         replace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1031\u001b[0m         p\u001b[39m=\u001b[39msample_weight \u001b[39m/\u001b[39m sample_weight\u001b[39m.\u001b[39msum(),\n\u001b[1;32m   1032\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine_Learning_For_Security_Solutions/MLSecuritySolutions/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:255\u001b[0m, in \u001b[0;36m_kmeans_plusplus\u001b[0;34m(X, n_clusters, x_squared_norms, sample_weight, random_state, n_local_trials)\u001b[0m\n\u001b[1;32m    252\u001b[0m np\u001b[39m.\u001b[39mclip(candidate_ids, \u001b[39mNone\u001b[39;00m, closest_dist_sq\u001b[39m.\u001b[39msize \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, out\u001b[39m=\u001b[39mcandidate_ids)\n\u001b[1;32m    254\u001b[0m \u001b[39m# Compute distances to center candidates\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m distance_to_candidates \u001b[39m=\u001b[39m _euclidean_distances(\n\u001b[1;32m    256\u001b[0m     X[candidate_ids], X, Y_norm_squared\u001b[39m=\u001b[39;49mx_squared_norms, squared\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    257\u001b[0m )\n\u001b[1;32m    259\u001b[0m \u001b[39m# update closest distances squared and potential for each candidate\u001b[39;00m\n\u001b[1;32m    260\u001b[0m np\u001b[39m.\u001b[39mminimum(closest_dist_sq, distance_to_candidates, out\u001b[39m=\u001b[39mdistance_to_candidates)\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine_Learning_For_Security_Solutions/MLSecuritySolutions/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:382\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    380\u001b[0m     distances \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m XX\n\u001b[1;32m    381\u001b[0m     distances \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m YY\n\u001b[0;32m--> 382\u001b[0m np\u001b[39m.\u001b[39;49mmaximum(distances, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mdistances)\n\u001b[1;32m    384\u001b[0m \u001b[39m# Ensure that distances between vectors and themselves are set to 0.0.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[39m# This may not be the case due to floating point rounding errors.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m Y:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use k means\n",
    "\n",
    "#from sklearn.cluster import KMeans\n",
    "\n",
    "#kmeans = KMeans(n_clusters=4000, random_state=0).fit(data_train)\n",
    "\n",
    "#predicted_test_labels = kmeans.predict(test_embeddings)\n",
    "#print(eval(predicted_test_labels))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72adc598-6d65-4c0f-a32a-a5ec2c61a088",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Once you have your 'predicted_test_labels' list, you can use the eval function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8398e8c-ac27-4452-b46f-2dffa74bbabf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_test_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/malcolmkrolick/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week 9/Final Practice.ipynb Cell 21\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/malcolmkrolick/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     accuracy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(targets\u001b[39m==\u001b[39mpredicted_test_labels)\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(predicted_test_labels)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/malcolmkrolick/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe accuracy of your system is \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m100\u001b[39m\u001b[39m*\u001b[39maccuracy\u001b[39m}\u001b[39;00m\u001b[39m%!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/malcolmkrolick/Documents/GitHub/Machine_Learning_For_Security_Solutions/Week%209/Final%20Practice.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39meval\u001b[39m(predicted_test_labels)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted_test_labels' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "819c1926-8047-4523-948b-a01b743bf24b",
   "metadata": {},
   "source": [
    "Our accuracy is not great right now, because we accept everyone! but I'm sure you can improve from there! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794adde4-2b83-4454-a1e8-b95cb69cbd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "#X = connection_embeddings[:,0]\n",
    "#Y = connection_embeddings[:,1]\n",
    "\n",
    "#labels = np.array(connections['logins'])\n",
    "#true_attempt = np.array(connections['true_attempt'])\n",
    "#size=5\n",
    "\n",
    "##ax_1 = plt.subplot(221) #First plot\n",
    "#for i in set(labels):\n",
    "#    ax_1.scatter(X[labels==i], Y[labels==i], label=i, s=size)\n",
    "#ax_1.set_title(\"Scatterplot by login used\")\n",
    "    \n",
    "#ax_2 = plt.subplot(222) #Second plot\n",
    "#ax_2.scatter(X[true_attempt==False], Y[true_attempt==False], label='False', s=size)\n",
    "##ax_2.scatter(X[true_attempt], Y[true_attempt], label='True', s=size)\n",
    "#ax_2.set_title(\"Scatterplot by true/false attempt\")\n",
    "#ax_2.legend()\n",
    "\n",
    "\n",
    "#ax_3 = plt.subplot(212)#third plot\n",
    "#true_scores = list(connections[connections['true_attempt']==True]['scores'])\n",
    "#false_scores = list(connections[connections['true_attempt']==False]['scores'])\n",
    "#ax_3.hist(false_scores, label='False Scores', bins=100, alpha=0.5)\n",
    "#ax_3.hist(true_scores,  label='True Scores',  bins=100, alpha=0.5)\n",
    "#ax_3.set_title(\"Scores\")\n",
    "#ax_3.legend()\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
