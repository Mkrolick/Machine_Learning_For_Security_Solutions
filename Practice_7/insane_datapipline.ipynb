{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def load_files(csv_file=\"\",npy_file=\"\"): return pd.read_csv(csv_file), np.load(npy_file, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 256) (10000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logins</th>\n",
       "      <th>passwords</th>\n",
       "      <th>ips</th>\n",
       "      <th>dates</th>\n",
       "      <th>true_attempt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>malik_antonia@email.com</td>\n",
       "      <td>Spenc&amp;r4Ever</td>\n",
       "      <td>170.252.165.242</td>\n",
       "      <td>20:22:59 25-12-2020</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>josue_mariam@email.com</td>\n",
       "      <td>03031974</td>\n",
       "      <td>193.251.224.173</td>\n",
       "      <td>04:45:06 11-04-2022</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>laila_delilah@email.com</td>\n",
       "      <td>LDE1ILAH76</td>\n",
       "      <td>34.5.41.175</td>\n",
       "      <td>11:11:55 07-04-2023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>charles_eliyahu@email.com</td>\n",
       "      <td>PATRICK1985</td>\n",
       "      <td>132.245.193.248</td>\n",
       "      <td>07:46:50 18-01-2022</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sade_miguel@email.com</td>\n",
       "      <td>pRw1wPP</td>\n",
       "      <td>34.113.135.64</td>\n",
       "      <td>17:32:41 23-03-2023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      logins     passwords              ips  \\\n",
       "0    malik_antonia@email.com  Spenc&r4Ever  170.252.165.242   \n",
       "1     josue_mariam@email.com      03031974  193.251.224.173   \n",
       "2    laila_delilah@email.com    LDE1ILAH76      34.5.41.175   \n",
       "3  charles_eliyahu@email.com   PATRICK1985  132.245.193.248   \n",
       "4      sade_miguel@email.com       pRw1wPP    34.113.135.64   \n",
       "\n",
       "                 dates  true_attempt  \n",
       "0  20:22:59 25-12-2020         False  \n",
       "1  04:45:06 11-04-2022         False  \n",
       "2  11:11:55 07-04-2023         False  \n",
       "3  07:46:50 18-01-2022         False  \n",
       "4  17:32:41 23-03-2023         False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connections, embeddings = load_files(csv_file=\"connections.csv\", npy_file=\"connections_embeddings.npy\")\n",
    "print(embeddings.shape, connections.shape)\n",
    "connections.head()\n",
    "\n",
    "labels_list = [1 if connection_true else 0 for connection_true in connections['true_attempt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#accuracies = []\n",
    "#neighbors = []\n",
    "#for N in tqdm(range(1,30)):\n",
    "    #clf = DecisionTreeClassifier(max_depth=N)\n",
    "    #clf.fit(data_train, labels_train)\n",
    "    #score = clf.score(data_test, labels_test)\n",
    "    #neighbors.append(N)\n",
    "    #accuracies.append(score)\n",
    "    \n",
    "\n",
    "\n",
    "#plt.plot(neighbors, accuracies)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels_list = [1 if connection_true else 0 for connection_true in connections['true_attempt']]\n",
    "labels = np.array(labels_list) #we transform the list in a np.array to ease the next steps (idk why, but sklearn seems to like it...)\n",
    "#data_train, data_test, labels_train, labels_test = train_test_split(embeddings, labels, test_size=0.20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensoflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout, Layer\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = Sequential([Dense(ff_dim, activation='relu'), Dense(embed_dim)])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "    \n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "    \n",
    "vocab_size = 20000\n",
    "maxlen = 200\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val) = imdb.load_data(num_words=vocab_size)\n",
    "print(len(x_train), 'Training sequences')\n",
    "print(len(x_val), 'Validation sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = tf.keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHAT IF WE DONT USE THE EMBEDDING AND WE JUST USE NLP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLSecuritySolutions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
